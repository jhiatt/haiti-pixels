---
title: "Disaster Relief Project: Part I"
author: "Jordan Hiatt"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  html_document:
    number_sections: true    
    toc: true
    toc_float: true
    theme: cosmo
    highlight: espresso    
# You can make the format personal - this will get you started:  
# https://bookdown.org/yihui/rmarkdown/html-document.html#appearance_and_style    
---

<!--- Below are global settings for knitr. You can override any of them by adding the changes to individual chunks --->

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 5.5,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "49%", # set width of displayed images
                      warning=TRUE,      # show R warnings
                      message=TRUE)      # show R messages
```

<!--- Change font sizes (or other css modifications) --->
<style>
h1.title {
  font-size: 2.2em; /* Title font size */
}
h1 {
  font-size: 2em;   /* Header 1 font size */
}
h2 {
  font-size: 1.5em;
}
h3 { 
  font-size: 1.2em;
}
pre {
  font-size: 0.8em;  /* Code and R output font size */
}
</style>



**SYS 6018 | Spring 2021 | University of Virginia **

*******************************************

# Introduction 

Tell the reader what this project is about. Motivation. 

# Training Data / EDA

Load data, explore data, etc. 

```{r load-packages, warning=FALSE, message=FALSE}
# Load Required Packages
library(tidyverse)
library(broom)
```

# Model Training

## Set-up 

```{r load-data}
# load in csv
data <- read.csv('HaitiPixels.csv',colClasses=c("factor",rep("numeric",3))) # for help with colClasses and rep() https://stackoverflow.com/questions/2805357/specifying-colclasses-in-the-read-csv

# gather general csv data
data %>% dim()
data %>% filter(is.na(data))
# classes
data$Class %>% contrasts()
data %>% filter(Class=='Blue Tarp') %>% dim()
data %>% filter(Class=='Rooftop') %>% dim()
data %>% filter(Class=='Soil') %>% dim()
data %>% filter(Class=='Various Non-Tarp') %>% dim()
data %>% filter(Class=='Vegetation') %>% dim()

# Combine classes
data <- data %>% mutate(Class.cl = ifelse(Class=='Blue Tarp','Blue Tarp','Other'))
data$Class.cl <- data$Class.cl %>% as_factor()
data$Class.cl %>% contrasts()


## set up 10-fold cross-validation
set.seed(42)
# First we get the number of items in each fold, then we get an index number cutt off for each fold if we were to number observations 1 to n
foldcount <- floor(dim(data)[1]/10) # this should give us the correct number of observations in each fold
# we need to make sure there is no top end or the last observation would be missed due to rounding, so we stop at 9
cuttoff_list <- list()
for(i in 1:9){
  cuttoff_list <- cuttoff_list %>% append(foldcount*i)
}

# create function for assigning folds
# really slow needs to be updated
assign_fold <- function(id) {
  if (id<cuttoff_list[1]) {
    return(1)
  } else if (id<cuttoff_list[2]) {
    return(2)
  } else if (id<cuttoff_list[3]) {
    return(3)
  } else if (id<cuttoff_list[4]) {
    return(4)
  } else if (id<cuttoff_list[5]) {
    return(5)
  } else if (id<cuttoff_list[6]) {
    return(6)
  } else if (id<cuttoff_list[7]) {
    return(7)
  } else if (id<cuttoff_list[8]) {
    return(8)
  } else if (id<cuttoff_list[9]) {
    return(9)
  } else {
    return(10)
  }
}

data.kfold <- data %>% mutate(random_id = sample(1:dim(data)[1], size = dim(data)[1], replace = FALSE), fold = 10) # sample without replacement: https://stackoverflow.com/questions/14864275/randomize-w-no-repeats-using-r

for(i in 1:dim(data.kfold)[1]){
  data.kfold[i,]$fold = assign_fold(data.kfold[i,]$random_id)
}

# for(i in 1:length(cuttoff_list)){
#   f <- paste0('fold0',i)
#   data.kfold <- data.kfold %>% purrr::map(if(random_id<cuttoff_list[[i]]){fold = f})
# }
#data.kfold <- data.kfold %>% mutate(fold = )
#kfold <- data %>% vfold_cv(v = 10, repeats = 1) # https://rsample.tidymodels.org/reference/vfold_cv.html
```
```{r}
data.kfold %>% filter(fold==1) %>% dim()
data.kfold %>% filter(fold==2) %>% dim()
data.kfold %>% filter(fold==3) %>% dim()
data.kfold %>% filter(fold==4) %>% dim()
data.kfold %>% filter(fold==5) %>% dim()
data.kfold %>% filter(fold==6) %>% dim()
data.kfold %>% filter(fold==7) %>% dim()
data.kfold %>% filter(fold==8) %>% dim()
data.kfold %>% filter(fold==9) %>% dim()
data.kfold %>% filter(fold==10) %>% dim()
```

It looks like these folds are evenly split

## Logistic Regression

```{r logistic-regression}
# create a loop for each fold cv and several different thresholds?? Use ROC curve to identify threshold (USE PRECISION FOR ROC)
#res.logisitic <- tibble(tuning=character(),actual=factor(),prediction=numeric()) # what do I need for the roc cuve, etc  REMOVE????

#goal, get predictions

# loop through k folds
cross_val <- function(kfold) {
  logistic.fit <- glm(Class.cl~Red+Green+Blue,family = binomial, data = data.kfold, subset=fold!=kfold)
  #logistic.fit %>% augment(newdata=filter(data.kfold$fold == kfold))
  holdout <- filter(data.kfold, fold == kfold)
  predictions <- logistic.fit %>% predict(holdout, type='response')
  # return actual, then predictions
  return(data_frame(fold=i,actual=holdout$Class.cl,prediction=predictions))
}

logistic.pred <- data_frame(fold=numeric(),actual=factor(),prediction=numeric())
for (i in 1:10) {
  logistic.pred<-full_join(logistic.pred, cross_val(i))
  
}

# kfold$splits %>% purrr::map(split_model) 


# models.logist <- kfold_model(data.df, 'Class.cl~Red+Green+Blue', 'lm')



# sci kit learn, tidymodels (new version of caret) (yardstick for confusion matrix)
# Output of the loop:
#   training models
#   predictions
#   output - data frame with predictions (in terms of probabilities), actuals, name of iteration




```

## LDA

## QDA

## KNN

### Tuning Parameter $k$

How were tuning parameter(s) selected? What value is used? Plots/Tables/etc.

## Penalized Logistic Regression (ElasticNet)

### Tuning Parameters

**NOTE: PART II same as above plus add Random Forest and SVM to Model Training.**

## Threshold Selection


# Results (Cross-Validation)

** CV Performance Table Here**


# Conclusions

### Conclusion \#1 

### Conclusion \#2

### Conclusion \#3


```{r, echo=FALSE}
# knitr::knit_exit()    # ignore everything after this
## Uncomment this line for Part I
## You can remove the entire code chunk for Part II
```


# Hold-out Data / EDA

Load data, explore data, etc. 


# Results (Hold-Out)

**Hold-Out Performance Table Here**


# Final Conclusions

### Conclusion \#1 

### Conclusion \#2

### Conclusion \#3

### Conclusion \#4 

### Conclusion \#5

### Conclusion \#6
